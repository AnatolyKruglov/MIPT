{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP, DS-поток\n",
    "## Задание 3\n",
    "### Transformers.\n",
    "\n",
    "**Правила:**\n",
    "\n",
    "* Дедлайны см. в боте. После дедлайна работы не принимаются кроме случаев наличия уважительной причины.\n",
    "* Выполненную работу нужно отправить телеграм-боту `@miptstats_ds23_bot`. Для начала работы с ботом каждый раз отправляйте `/start`. Дождитесь подтверждения от бота, что он принял файл. Если подтверждения нет, то что-то не так. **Работы, присланные иным способом, не принимаются.**\n",
    "* Дедлайны см. в боте. После дедлайна работы не принимаются кроме случаев наличия уважительной причины.\n",
    "* Прислать нужно **ноутбук в формате `ipynb`**.\n",
    "* Следите за размером файлов. **Бот не может принимать файлы весом более 20 Мб.** Если файл получается больше, заранее разделите его на несколько.\n",
    "* Выполнять задание необходимо полностью самостоятельно. **При обнаружении списывания все участники списывания получат штраф.**\n",
    "* Решения, размещенные на каких-либо интернет-ресурсах, не принимаются. Кроме того, публикация решения в открытом доступе может быть приравнена к предоставлении возможности списать.\n",
    "* Для выполнения задания используйте этот ноутбук в качестве основы, ничего не удаляя из него. Можно добавлять необходимое количество ячеек.\n",
    "* Комментарии к решению пишите в markdown-ячейках.\n",
    "* Выполнение задания (ход решения, выводы и пр.) должно быть осуществлено на русском языке.\n",
    "* Если код будет не понятен проверяющему, оценка может быть снижена.\n",
    "* Никакой код из данного задания при проверке запускаться не будет. *Если код студента не выполнен, недописан и т.д., то он не оценивается.*\n",
    "* В каждой задаче не забывайте делать **пояснения и выводы**.\n",
    "* **Код из рассказанных на занятиях ноутбуков** можно использовать без ограничений.\n",
    "\n",
    "\n",
    "**Правила оформления теоретических задач:**\n",
    "\n",
    "* Решения необходимо прислать одним из следующих способов:\n",
    "  * фотографией в правильной ориентации, где все четко видно, а почерк разборчив,\n",
    "    * отправив ее как файл боту вместе с ноутбуком *или*\n",
    "    * вставив ее в ноутбук посредством `Edit -> Insert Image` (<font color=\"red\">фото, вставленные ссылкой, не принимаются</font>);\n",
    "  * в виде $LaTeX$ в markdown-ячейках.\n",
    "* Решения не проверяются, если какое-то требование не выполнено. Особенно внимательно все проверьте в случае выбора второго пункта (вставки фото в ноутбук). <font color=\"red\"><b>Неправильно вставленные фотографии могут не передаться при отправке.</b></font> Для проверки попробуйте переместить `ipynb` в другую папку и открыть его там.\n",
    "* В решениях поясняйте, чем вы пользуетесь, хотя бы кратко. Например, если пользуетесь независимостью, то достаточно подписи вида \"*X и Y незав.*\"\n",
    "* Решение, в котором есть только ответ, и отсутствуют вычисления, оценивается в 0 баллов.\n",
    "\n",
    "**Баллы за задание:**\n",
    "  * Работа с данными, токенизация, реализация метрики &mdash; 20 баллов;\n",
    "  * Реализация модели &mdash; 20 баллов;\n",
    "  * Реализация пайплайна &mdash; 60 баллов;\n",
    "  * MLM &mdash; 50 баллов.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-13T10:37:04.138867Z",
     "iopub.status.busy": "2025-03-13T10:37:04.138502Z",
     "iopub.status.idle": "2025-03-13T10:37:04.142620Z",
     "shell.execute_reply": "2025-03-13T10:37:04.141480Z",
     "shell.execute_reply.started": "2025-03-13T10:37:04.138838Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Bot check\n",
    "\n",
    "# HW_ID: ds_nlp3\n",
    "# Бот проверит этот ID и предупредит, если случайно сдать что-то не то.\n",
    "\n",
    "# Status: final\n",
    "# Перед отправкой в финальном решении удали \"not\" в строчке выше.\n",
    "# Так бот проверит, что ты отправляешь финальную версию, а не промежуточную.\n",
    "# Никакие значения в этой ячейке не влияют на факт сдачи работы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-13T10:37:04.147592Z",
     "iopub.status.busy": "2025-03-13T10:37:04.147330Z",
     "iopub.status.idle": "2025-03-13T10:39:41.953934Z",
     "shell.execute_reply": "2025-03-13T10:39:41.953112Z",
     "shell.execute_reply.started": "2025-03-13T10:37:04.147561Z"
    },
    "id": "2NmNzKxxqZuP",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m797.2/797.2 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m98.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m77.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m37.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.4/209.4 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pylibcugraph-cu12 24.10.0 requires pylibraft-cu12==24.10.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\n",
      "pylibcugraph-cu12 24.10.0 requires rmm-cu12==24.10.*, but you have rmm-cu12 25.2.0 which is incompatible.\n",
      "torchaudio 2.5.1+cu121 requires torch==2.5.1, but you have torch 2.4.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets torch==2.4.0 torchvision==0.19.0 -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-13T10:39:41.955612Z",
     "iopub.status.busy": "2025-03-13T10:39:41.955301Z",
     "iopub.status.idle": "2025-03-13T10:39:52.006904Z",
     "shell.execute_reply": "2025-03-13T10:39:52.005914Z",
     "shell.execute_reply.started": "2025-03-13T10:39:41.955581Z"
    },
    "id": "58sMD9a0oqG_",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import transformers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModel, DataCollatorWithPadding  #, TrainingArguments, Trainer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MQzbcSPAorPc"
   },
   "source": [
    "### Описание задачи\n",
    "В этом домашнем задании мы будем работать с данными с [соревнования](https://boosters.pro/championship/HeadHunter/overview) от HeadHunter. Нам предстоит предсказать причины которые закодированы числами от 1 до 8, по которым отзыв на работадателя не проходит модерацию. Причин, по которым отзыв не прошёл модерацию может быть несколько. Если отзыв проходит модерацию, то вместо причины отказа нужно предсказывать 0. Значение 0 разрешается комбинировать с причинами отказа. \n",
    "\n",
    "Таким образом, мы имеем дело с задачей *multi-label классификации*. \n",
    "Самый простой и популярный способ работать с multi-label задачей классификации &mdash; перейти к бинарной. Для каждого класса мы ставим метку 1, если он присутствует в таргете, а 0 &mdash; иначе. В процессе обучения мы будем минимизировать бинарную кросс-энтропию.\n",
    "\n",
    "В качестве целевой метрики будем использовать $F_1$-score с усреднением по сэмплам.\n",
    "\n",
    "$$\n",
    "F_1 = \\frac{1}{n}\\sum_{i=1}^n 2\\frac{precision_i recall_i}{precision_i + recall_i},\n",
    "$$\n",
    "где $n$ &mdash; размер выборки, а $precision_i, recall_i$ &mdash; precision/recall для i-го объекта."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JEVW5B5EuJbk"
   },
   "source": [
    "### Работа с данными\n",
    "\n",
    "Загрузите обучающий датасет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 333
    },
    "execution": {
     "iopub.execute_input": "2025-03-13T10:39:52.009318Z",
     "iopub.status.busy": "2025-03-13T10:39:52.008770Z",
     "iopub.status.idle": "2025-03-13T10:39:52.799562Z",
     "shell.execute_reply": "2025-03-13T10:39:52.798608Z",
     "shell.execute_reply.started": "2025-03-13T10:39:52.009295Z"
    },
    "id": "oM1MNQUmo65E",
    "outputId": "001ccc44-ad7b-4a99-dc84-10b274dbec01",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>city</th>\n",
       "      <th>position</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>salary_rating</th>\n",
       "      <th>team_rating</th>\n",
       "      <th>managment_rating</th>\n",
       "      <th>career_rating</th>\n",
       "      <th>workplace_rating</th>\n",
       "      <th>rest_recovery_rating</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Ижевск</td>\n",
       "      <td>Кладовщик</td>\n",
       "      <td>Недавно устроился в ****** на должность кладов...</td>\n",
       "      <td>Повысить з/п</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Москва</td>\n",
       "      <td>Руководитель проекта</td>\n",
       "      <td>Расположение офиса, своего рода стабильность (...</td>\n",
       "      <td>Упростить процессы - все процессы ради процесс...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Екатеринбург</td>\n",
       "      <td>Консультант</td>\n",
       "      <td>В нашем банке все по закону в плане зарплаты и...</td>\n",
       "      <td>Ничего</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_id          city              position  \\\n",
       "0          0        Ижевск             Кладовщик   \n",
       "1          1        Москва  Руководитель проекта   \n",
       "2          2  Екатеринбург           Консультант   \n",
       "\n",
       "                                            positive  \\\n",
       "0  Недавно устроился в ****** на должность кладов...   \n",
       "1  Расположение офиса, своего рода стабильность (...   \n",
       "2  В нашем банке все по закону в плане зарплаты и...   \n",
       "\n",
       "                                            negative  salary_rating  \\\n",
       "0                                       Повысить з/п              5   \n",
       "1  Упростить процессы - все процессы ради процесс...              4   \n",
       "2                                             Ничего              5   \n",
       "\n",
       "   team_rating  managment_rating  career_rating  workplace_rating  \\\n",
       "0            4                 3              3                 4   \n",
       "1            4                 4              1                 1   \n",
       "2            5                 5              5                 5   \n",
       "\n",
       "   rest_recovery_rating target  \n",
       "0                     4      0  \n",
       "1                     1      8  \n",
       "2                     5      0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"/kaggle/input/headhunter-train/HeadHunter_train.csv\")\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q5i0pu34rUn6"
   },
   "source": [
    "Как можно увидеть, помимо положительного `positive` и отрицательного `negative` текста отзывов, мы также имеем некоторое количество категориальных признаков, с которыми мы пока не будем работать. Целевая переменная расположена в колонке `target` и представляет из себя строку, разделенную запятыми. \n",
    "\n",
    "Посмотрим, какие значения может принимать целевая переменная."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-03-13T10:39:52.801085Z",
     "iopub.status.busy": "2025-03-13T10:39:52.800812Z",
     "iopub.status.idle": "2025-03-13T10:39:52.812060Z",
     "shell.execute_reply": "2025-03-13T10:39:52.811373Z",
     "shell.execute_reply.started": "2025-03-13T10:39:52.801064Z"
    },
    "id": "d8e4_qWHq_Wt",
    "outputId": "4fbdd2ac-6bf4-4baa-f24c-ab2d063e3d60",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0', '8', '7', '1,8', '3,8', '6,8', '6', '3', '1', '1,6', '4,8',\n",
       "       '5', '5,8', '1,5', '7,8', '4', '5,6', '1,4', '1,6,8', '1,7',\n",
       "       '1,5,8', '1,3,8', '1,3', '1,4,6', '4,6', '1,3,5', '3,5,8', '1,5,6',\n",
       "       '1,4,8', '1,2,6', '5,7', '3,5', '5,6,8', '1,3,6', '3,7', '2',\n",
       "       '1,7,8', '3,6,8', '6,7', '4,6,8', '5,7,8', '3,6', '1,5,6,8',\n",
       "       '3,5,7'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"target\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wB1-wQV0sTll"
   },
   "source": [
    "Посмотрим на примеры отзывов, которые не прошли модерацию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "execution": {
     "iopub.execute_input": "2025-03-13T10:39:52.813071Z",
     "iopub.status.busy": "2025-03-13T10:39:52.812881Z",
     "iopub.status.idle": "2025-03-13T10:39:52.836169Z",
     "shell.execute_reply": "2025-03-13T10:39:52.835491Z",
     "shell.execute_reply.started": "2025-03-13T10:39:52.813055Z"
    },
    "id": "yTwSXv6nsTTQ",
    "outputId": "f7aa10bf-76ee-482b-bb39-bd04a36c076a",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Известная компания.....................................................................................................'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data[\"target\"] == \"5,8\"][\"positive\"].values[13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "execution": {
     "iopub.execute_input": "2025-03-13T10:39:52.837194Z",
     "iopub.status.busy": "2025-03-13T10:39:52.836949Z",
     "iopub.status.idle": "2025-03-13T10:39:52.857364Z",
     "shell.execute_reply": "2025-03-13T10:39:52.856539Z",
     "shell.execute_reply.started": "2025-03-13T10:39:52.837165Z"
    },
    "id": "2c16ldlysFIG",
    "outputId": "72898475-d4aa-488f-99f8-86c4f19594d5",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Хужбвб влвлв в вщвлу у улыды ыыд'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data[\"target\"] == \"3,8\"][\"positive\"].values[29]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eYMqsk4DvVi_"
   },
   "source": [
    "Для дальнейшей работы избавьтесь от ненужных колонок, а также преобразуйте строковую целевую переменную в удобный для работы формат в виде матрицы, где каждому объекту будет сопоставлен вектор размерности 9, в котором на позиции $i$ будет стоять 1, если $i$ встречаетcя в текстовом поле `target`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-13T10:39:52.858314Z",
     "iopub.status.busy": "2025-03-13T10:39:52.858085Z",
     "iopub.status.idle": "2025-03-13T10:39:53.144135Z",
     "shell.execute_reply": "2025-03-13T10:39:53.143220Z",
     "shell.execute_reply.started": "2025-03-13T10:39:52.858296Z"
    },
    "id": "K3MSef84um4H",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>target_0</th>\n",
       "      <th>target_1</th>\n",
       "      <th>target_2</th>\n",
       "      <th>target_3</th>\n",
       "      <th>target_4</th>\n",
       "      <th>target_5</th>\n",
       "      <th>target_6</th>\n",
       "      <th>target_7</th>\n",
       "      <th>target_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Недавно устроился в ****** на должность кладов...</td>\n",
       "      <td>Повысить з/п</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Расположение офиса, своего рода стабильность (...</td>\n",
       "      <td>Упростить процессы - все процессы ради процесс...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>В нашем банке все по закону в плане зарплаты и...</td>\n",
       "      <td>Ничего</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            positive  \\\n",
       "0  Недавно устроился в ****** на должность кладов...   \n",
       "1  Расположение офиса, своего рода стабильность (...   \n",
       "2  В нашем банке все по закону в плане зарплаты и...   \n",
       "\n",
       "                                            negative  target_0  target_1  \\\n",
       "0                                       Повысить з/п         1         0   \n",
       "1  Упростить процессы - все процессы ради процесс...         0         0   \n",
       "2                                             Ничего         1         0   \n",
       "\n",
       "   target_2  target_3  target_4  target_5  target_6  target_7  target_8  \n",
       "0         0         0         0         0         0         0         0  \n",
       "1         0         0         0         0         0         0         1  \n",
       "2         0         0         0         0         0         0         0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[['positive','negative','target']]\n",
    "for i in range(9):\n",
    "    data[f'target_{i}'] = data['target'].apply(lambda x: i in [int(a) for a in x.split(',')]).astype(int)\n",
    "data.drop('target', axis=1, inplace=True)\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R7cR8Oxuw6L6"
   },
   "source": [
    "Разделите выборку на обучающую и валидационную."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-13T10:39:53.147056Z",
     "iopub.status.busy": "2025-03-13T10:39:53.146761Z",
     "iopub.status.idle": "2025-03-13T10:39:53.167603Z",
     "shell.execute_reply": "2025-03-13T10:39:53.166756Z",
     "shell.execute_reply.started": "2025-03-13T10:39:53.147035Z"
    },
    "id": "RBtbILHhwno8",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_data, val_data, train_labels, val_labels = train_test_split(data[['positive','negative']], data[[f'target_{i}' for i in range(9)]], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nHNi4Uc9xInh"
   },
   "source": [
    "### Токенизация и реализация метрики качества\n",
    "\n",
    "Теперь реализуем вышеупомянутую метрику, а именно $F_1$-score с усреднением по сэмплам. Подумайте, как поступить, если для какого-то из объектов $precision=recall=0$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-13T10:39:53.169240Z",
     "iopub.status.busy": "2025-03-13T10:39:53.169031Z",
     "iopub.status.idle": "2025-03-13T10:39:53.174689Z",
     "shell.execute_reply": "2025-03-13T10:39:53.173882Z",
     "shell.execute_reply.started": "2025-03-13T10:39:53.169223Z"
    },
    "id": "St7LHBksxTwZ",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def calculate_f1_score(preds, targets):\n",
    "    \"\"\"Подсчет F1-score с усреднением по сэмплам.\n",
    "    :param preds: np.array размерности (n, 9), содержит в себе предсказания в виде бинарной метки 0/1 для каждого класса\n",
    "    :param preds: np.array размерности (n, 9), истинные бинарные таргеты\n",
    "    \"\"\"\n",
    "    # F1s = []\n",
    "    # for i in range(preds.shape[1]):\n",
    "    #     tp, fp, fn = preds[:,i] @ targets[:,i], preds[:,i] @ (1-targets[:,i]), (1-preds[:,i]) @ targets[:,i]\n",
    "    #     P, R = tp/(tp+fp) if tp+fp > 0 else 0, tp/(tp+fn) if tp+fn > 0 else 0\n",
    "    #     F1s.append(2*P*R/(P+R) if P+R > 0 else 0)\n",
    "    # return np.mean(F1s)\n",
    "    tp, fp, fn = np.sum(preds*targets, axis=0), np.sum(preds*(1-targets), axis=0), np.sum((1-preds)*targets, axis=0)\n",
    "    P, R = tp/(tp+fp) if np.any(tp+fp>0) else 0, tp/(tp+fn) if np.any(tp+fn>0) else 0\n",
    "    F1s = 2*P*R/(P+R) if np.any(P+R>0) else 0\n",
    "    return np.mean(F1s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6s9L4dOQzXaS"
   },
   "source": [
    "В этом задании предлагается использовать библиотеку `transformers`, а значит позаботиться о токенизации надо заранее, ведь токенизаторы у разных моделей могут отличаться. Вы можете использовать любую модель, которая умеет работать с русским языком. Рекомендуем обратить внимания на следующие:\n",
    "\n",
    "* [ruBert-base](https://huggingface.co/sberbank-ai/ruBert-base)  \n",
    "* [rubert-base-cased](https://huggingface.co/DeepPavlov/rubert-base-cased)  - *возьмем эту*  \n",
    "* [distilrubert-base-cased-conversational](https://huggingface.co/DeepPavlov/distilrubert-base-cased-conversational)\n",
    "* [rubert-tiny](https://habr.com/ru/post/562064/)\n",
    "* [ruRoberta-large](https://huggingface.co/sberbank-ai/ruRoberta-large/)\n",
    "\n",
    "Учтите, что некоторые из моделей могут потребовать значительных ресурсов GPU. Для обучения рекомендуем использовать Colab или Kaggle. Самая легкая и быстрая модель из перечисленных &mdash; это `rubert-tiny`, можете для простоты использовать ее.\n",
    "\n",
    "На вход модели предлагается подавать последовательность следующего вида: `[CLS] positive [SEP] negative [SEP]`, где `positive` и `negative` &mdash; тексты положительной и отрицательной части отзыва, разделенные спец. токеном `[SEP]`, получить который можно через `tokenizer.sep_token`. То есть мы сразу подаем в энкодер тексты обеих частей отзыва и пытаемся предсказать результат модерации. После применения энкодера скрытое состояние, соответствующее токену `[CLS]`, будет содержать информацию о содержании отзыва. После этого, просто используя линейный слой, мы сможем сделать предсказание для 9 классов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-13T10:39:53.176036Z",
     "iopub.status.busy": "2025-03-13T10:39:53.175665Z",
     "iopub.status.idle": "2025-03-13T10:40:58.786927Z",
     "shell.execute_reply": "2025-03-13T10:40:58.785965Z",
     "shell.execute_reply.started": "2025-03-13T10:39:53.176005Z"
    },
    "id": "y8rR58Rp-V98",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('DeepPavlov/rubert-base-cased')\n",
    "\n",
    "# соединим две части отзыва. Токен CLS и второй SEP добавит токенизатор\n",
    "train_concatenated = [f\"{x.positive} {tokenizer.sep_token} {x.negative}\" for _,x in train_data.iterrows()]\n",
    "val_concatenated = [f\"{x.positive} {tokenizer.sep_token} {x.negative}\" for _,x in val_data.iterrows()]\n",
    "\n",
    "# Токенизация\n",
    "train_encodings = tokenizer(train_concatenated, truncation=True, padding=True, return_tensors='pt')\n",
    "val_encodings = tokenizer(val_concatenated, truncation=True, padding=True, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l7gPhFRqHgU_"
   },
   "source": [
    "Создадим датасет, используя `datasets.Dataset` и метод `.from_dict(...)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-13T10:40:58.788274Z",
     "iopub.status.busy": "2025-03-13T10:40:58.787943Z",
     "iopub.status.idle": "2025-03-13T10:40:59.031317Z",
     "shell.execute_reply": "2025-03-13T10:40:59.030364Z",
     "shell.execute_reply.started": "2025-03-13T10:40:58.788238Z"
    },
    "id": "Muk8GofZB3t4",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_dict({\"text\": train_concatenated, \"labels\": train_labels.to_numpy()})\n",
    "val_dataset = Dataset.from_dict({\"text\": val_concatenated, \"labels\": val_labels.to_numpy()})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iq_1Pe0WHs35"
   },
   "source": [
    "Наш датасет содержит тексты и метки к ним. Для дальнешей работы тексты нужно токенизировать, для этого воспользуемся методом `map` у датасета."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-13T10:40:59.032512Z",
     "iopub.status.busy": "2025-03-13T10:40:59.032201Z",
     "iopub.status.idle": "2025-03-13T10:41:17.492088Z",
     "shell.execute_reply": "2025-03-13T10:41:17.491082Z",
     "shell.execute_reply.started": "2025-03-13T10:40:59.032480Z"
    },
    "id": "VTUJ1JerIMUM",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dd80e35a1484ccabf53f5956834ab25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/40700 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaf025a3bd2d4fadb9c25ec96629b267",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10176 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset = train_dataset.map(  # применяем функцию к каждому элементу датасета\n",
    "    lambda elem: tokenizer(\n",
    "        elem[\"text\"],               # токенизируем поле text\n",
    "        add_special_tokens=True,    # автоматически добавляем CLS, SEP токены\n",
    "        truncation=True,            # обрезаем ли последовательность\n",
    "        max_length=256,             # ограничение на длину, надо выставить разумно? :)\n",
    "    ),\n",
    ")\n",
    "val_dataset = val_dataset.map(\n",
    "    lambda elem: tokenizer(\n",
    "        elem[\"text\"],\n",
    "        add_special_tokens=True,  \n",
    "        truncation=True,          \n",
    "        max_length=256,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1pNLM2OWI5qz"
   },
   "source": [
    "Посмотрим на элемент нашего датасета."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-13T10:41:17.493379Z",
     "iopub.status.busy": "2025-03-13T10:41:17.493053Z",
     "iopub.status.idle": "2025-03-13T10:41:17.502680Z",
     "shell.execute_reply": "2025-03-13T10:41:17.501985Z",
     "shell.execute_reply.started": "2025-03-13T10:41:17.493346Z"
    },
    "id": "QOx1oBzuI99x",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Ничего. Все плохо, мне ничего не нравится [SEP] Повысить зарплату и не вычитать за все подряд Не орать на сотрудников и не оскорблять',\n",
       " 'labels': [0, 0, 0, 0, 0, 0, 1, 0, 1],\n",
       " 'input_ids': [101,\n",
       "  64189,\n",
       "  132,\n",
       "  10351,\n",
       "  23108,\n",
       "  128,\n",
       "  16740,\n",
       "  14179,\n",
       "  1699,\n",
       "  37267,\n",
       "  102,\n",
       "  15719,\n",
       "  10650,\n",
       "  2603,\n",
       "  43541,\n",
       "  851,\n",
       "  1699,\n",
       "  76579,\n",
       "  2110,\n",
       "  1758,\n",
       "  4752,\n",
       "  16927,\n",
       "  9257,\n",
       "  52157,\n",
       "  4099,\n",
       "  1469,\n",
       "  13642,\n",
       "  851,\n",
       "  1699,\n",
       "  114846,\n",
       "  102],\n",
       " 'token_type_ids': [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'attention_mask': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jc2XvbzMJBlj"
   },
   "source": [
    "Как видим, помимо `input_ids`, которые отправятся на вход модели, у нас так же имеется `attention_mask`, а также в зависимости от модели могут быть `token_type_ids` &mdash; некоторые модели используют для задачи **NSP**.\n",
    "\n",
    "Вообще говоря, уже на этапе токенизации мы могли бы дополнить паддингом до максимальной длины наши последовательности, это можно сделать при вызове токенизатора, используя параметр `padding`. Однако у это подхода есть недостатки, поэтому эффективнее будет выполнить паддинг в даталоадере, на этапе формирования батча, тем самым дополнив все последовательности по длине до максимальной длины в батче.\n",
    "\n",
    "Подробнее о токенизаторах в `transformers` можно почитать по [ссылке](https://huggingface.co/docs/transformers/v4.26.1/en/main_classes/tokenizer).\n",
    "\n",
    "Посмотрим, как расположены спец токены:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-13T10:41:17.503963Z",
     "iopub.status.busy": "2025-03-13T10:41:17.503622Z",
     "iopub.status.idle": "2025-03-13T10:41:17.522878Z",
     "shell.execute_reply": "2025-03-13T10:41:17.522117Z",
     "shell.execute_reply.started": "2025-03-13T10:41:17.503942Z"
    },
    "id": "Elw_heKTKc5u",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] надежная компания. порядки здесь строгие, что хорошо. если работать исправно и не халявить то можно и премию отличную заработать.. официальное трудоустройство и полный соц пакет [SEP] к компании у меня претензий никаких нет. [SEP]'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(train_dataset[6][\"input_ids\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cm9OlXYeWbK1"
   },
   "source": [
    "Избавимся от теперь ненужного поля `text`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-13T10:41:17.524207Z",
     "iopub.status.busy": "2025-03-13T10:41:17.523866Z",
     "iopub.status.idle": "2025-03-13T10:41:17.542000Z",
     "shell.execute_reply": "2025-03-13T10:41:17.541290Z",
     "shell.execute_reply.started": "2025-03-13T10:41:17.524176Z"
    },
    "id": "o-29FrviWgq2",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_dataset, val_dataset = train_dataset.remove_columns(\"text\"), val_dataset.remove_columns(\"text\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UKEvgozuKniu"
   },
   "source": [
    "### Модель\n",
    "\n",
    "Реализуйте класс модели. В качестве классификатора используйте линейный слой, в который можно подать, например, эмбеддинг CLS-токена с последнего слоя, который можно получить следующим образом:\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "output = bert(input)\n",
    "cls_token = output.last_hidden_state[:, 0, :]\n",
    "logits = classifier(cls_token)\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-13T10:41:17.543254Z",
     "iopub.status.busy": "2025-03-13T10:41:17.542952Z",
     "iopub.status.idle": "2025-03-13T10:41:17.557907Z",
     "shell.execute_reply": "2025-03-13T10:41:17.557109Z",
     "shell.execute_reply.started": "2025-03-13T10:41:17.543222Z"
    },
    "id": "VRlbqkTCFuDy",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.bert = AutoModel.from_pretrained('DeepPavlov/rubert-base-cased')\n",
    "        self.classifier = nn.Linear(self.bert.config.hidden_size, 9)  # 9 классов\n",
    "        self.unfreeze()  # по умолчанию\n",
    "    def forward(self, batch):\n",
    "        output = self.bert(batch[\"input_ids\"])\n",
    "        cls_token = output.last_hidden_state[:, 0, :]\n",
    "        logits = self.classifier(cls_token)\n",
    "        return logits\n",
    "    def freeze(self):  # пригодится ниже\n",
    "        for param in self.bert.parameters():\n",
    "            param.requires_grad = False\n",
    "    def unfreeze(self):  # пригодится ниже\n",
    "        for param in self.bert.parameters():\n",
    "            param.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Q8w4LwhZ1Cv"
   },
   "source": [
    "Проверьте работоспособность модели простым тестом на размерность. В зависимости от реализации метода forward, код ниже стоит поменять, сохранив смысл."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-13T10:41:17.558952Z",
     "iopub.status.busy": "2025-03-13T10:41:17.558716Z",
     "iopub.status.idle": "2025-03-13T10:41:23.227109Z",
     "shell.execute_reply": "2025-03-13T10:41:23.225500Z",
     "shell.execute_reply.started": "2025-03-13T10:41:17.558932Z"
    },
    "id": "6zgy-el-YkSq",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at DeepPavlov/rubert-base-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "batch_size = 8\n",
    "dummy_input = {\"input_ids\" : torch.randint(0, 20000, (batch_size, 256))}\n",
    "model = Model()\n",
    "assert model(dummy_input).shape == (batch_size,9), model(dummy_input).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eoHjHJBHLu2i"
   },
   "source": [
    "### Пайплайн обучения\n",
    "\n",
    "1. Реализуйте пайплайн обучения и обучите модель. Попробуйте по желанию воспользоваться `Trainer`-ом и библиотеки `transformers`. Вам могут помочь примеры [здесь](https://huggingface.co/docs/transformers/training), [здесь](https://huggingface.co/learn/nlp-course/chapter3/3) и [здесь](https://github.com/huggingface/transformers/tree/main/examples/pytorch/text-classification). Учтите, что у нас задача *multi-label классификации*, которую мы свели к бинарной классификации нескольких меток, а значит нужно использовать **BCE-loss**. \n",
    "2. Cначала обучите только последний линейный слой, заморозив веса языковой модели, а затем всю модель целиком. Посчитайте качество на валидационной выборке и сравните результаты. \n",
    "\n",
    "Подумайте, как стоит выбирать порог для бинарной классификации. Что делать, если мы не предсказали никакой класс? Что можно сказать о результатах? \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*С Trainer почему-то не завелось( происходило обращение к w&b, но окно для ввода апи-ключа не появлялось (кажется, из-за бага со стороны кэгла)* \n",
    "  \n",
    "*Порог надо брать 0.5, чтобы сеть обучалась нормально, без информации о каких-либо сдвигах\\калибровках. В крайнем случае, можно будет пошатать порог уже после обучения, чтобы откалибровать готовую модель*  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z57ICYtHUPtE"
   },
   "source": [
    "В случае использования `transformers.Trainer` в него можно передать датасеты, а также `data collator` &mdash; объект, который непосредственно формирует батч по списку объектов из датасета. Обычно, в процессе формирования батча `data collator` может выполнять некоторой препроцессинг, например, паддинг или маскирование токенов в задаче **MLM**.\n",
    "\n",
    "Воспользуемся простым data collator-ом для паддинга наших текстов. Создадим даталоадеры для случая самописного кода обучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-13T10:41:23.230425Z",
     "iopub.status.busy": "2025-03-13T10:41:23.229241Z",
     "iopub.status.idle": "2025-03-13T10:41:23.236679Z",
     "shell.execute_reply": "2025-03-13T10:41:23.235900Z",
     "shell.execute_reply.started": "2025-03-13T10:41:23.230391Z"
    },
    "id": "QOk5eIE7VYvr",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, collate_fn=data_collator)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, collate_fn=data_collator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N7ZjzD2_W3AQ"
   },
   "source": [
    "Посмотрим на батч данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-03-13T10:41:23.237668Z",
     "iopub.status.busy": "2025-03-13T10:41:23.237430Z",
     "iopub.status.idle": "2025-03-13T10:41:23.298551Z",
     "shell.execute_reply": "2025-03-13T10:41:23.297859Z",
     "shell.execute_reply.started": "2025-03-13T10:41:23.237638Z"
    },
    "id": "djIhC9DLWEml",
    "outputId": "803031d1-f3c1-49c3-e30e-9b6958eb3461",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'labels': tensor([[1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 1, 0, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [0, 1, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 1]]), 'input_ids': tensor([[  101, 96265,  6070,  ...,     0,     0,     0],\n",
       "        [  101, 52877, 23442,  ...,     0,     0,     0],\n",
       "        [  101, 25292,   898,  ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [  101, 19470,  2190,  ...,     0,     0,     0],\n",
       "        [  101, 83813, 13301,  ...,     0,     0,     0],\n",
       "        [  101, 15393, 10556,  ...,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0]])}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-13T10:41:23.299445Z",
     "iopub.status.busy": "2025-03-13T10:41:23.299240Z",
     "iopub.status.idle": "2025-03-13T10:41:23.305673Z",
     "shell.execute_reply": "2025-03-13T10:41:23.304878Z",
     "shell.execute_reply.started": "2025-03-13T10:41:23.299428Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def loop(model, num_epochs=3, lr=3e-4):\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "    Loss = nn.BCEWithLogitsLoss()\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for batch in tqdm(train_loader):\n",
    "            loss = Loss(model({'input_ids':batch['input_ids'].cuda()}), batch[\"labels\"].float().cuda())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        del batch\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            outputs, targets = [], []\n",
    "            for batch in tqdm(val_loader):\n",
    "                outputs.append((torch.sigmoid(model({'input_ids':batch['input_ids'].cuda()})) > 0.5).int())\n",
    "                targets.append(batch[\"labels\"])\n",
    "            outputs, targets = torch.cat(outputs).cpu().numpy(), torch.cat(targets).cpu().numpy()\n",
    "            print(f'Эпоха {epoch}: F1 на валидации = {calculate_f1_score(outputs, targets):.3f}')\n",
    "            del batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Cначала заморозим тело, обучим голову (последний лин. слой)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-13T10:41:23.306979Z",
     "iopub.status.busy": "2025-03-13T10:41:23.306649Z",
     "iopub.status.idle": "2025-03-13T11:10:05.270225Z",
     "shell.execute_reply": "2025-03-13T11:10:05.269292Z",
     "shell.execute_reply.started": "2025-03-13T10:41:23.306956Z"
    },
    "id": "tatVUWP1OFbs",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at DeepPavlov/rubert-base-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "  0%|          | 0/636 [00:00<?, ?it/s]We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
      "100%|██████████| 636/636 [07:41<00:00,  1.38it/s]\n",
      "100%|██████████| 159/159 [01:50<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 0: F1 на валидации = 0.164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 636/636 [07:40<00:00,  1.38it/s]\n",
      "100%|██████████| 159/159 [01:50<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 1: F1 на валидации = 0.171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 636/636 [07:45<00:00,  1.37it/s]\n",
      "100%|██████████| 159/159 [01:50<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 2: F1 на валидации = 0.176\n"
     ]
    }
   ],
   "source": [
    "model = Model().cuda()\n",
    "model.freeze()\n",
    "loop(model)\n",
    "model.cpu()\n",
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ну, кстати, неплохо: что-то точно обучилось, метрика выросла. Возможно, стоит обучать побольше эпох (но gpu-usage в кэгле мне еще для cv понадобится), плюс наверняка есть дисбаланс классов, так что стоит посмотреть в сторону сэмплирования*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Теперь разморозим и обучим модель полностью*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-13T11:10:05.271712Z",
     "iopub.status.busy": "2025-03-13T11:10:05.271386Z",
     "iopub.status.idle": "2025-03-13T12:29:18.693707Z",
     "shell.execute_reply": "2025-03-13T12:29:18.692920Z",
     "shell.execute_reply.started": "2025-03-13T11:10:05.271688Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at DeepPavlov/rubert-base-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████| 636/636 [24:38<00:00,  2.33s/it]\n",
      "100%|██████████| 159/159 [01:48<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 0: F1 на валидации = 0.076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 636/636 [24:40<00:00,  2.33s/it]\n",
      "100%|██████████| 159/159 [01:47<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 1: F1 на валидации = 0.076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 636/636 [24:26<00:00,  2.31s/it]\n",
      "100%|██████████| 159/159 [01:48<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 2: F1 на валидации = 0.076\n"
     ]
    }
   ],
   "source": [
    "model = Model().cuda()\n",
    "model.unfreeze()\n",
    "loop(model)\n",
    "model.cpu()\n",
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Стало похуже. Кажется, данных слишком мало, чтобы обучать крупную сеть целиком, так что стоит брать претрейн и обучать только голову*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Beu0cYXfOGCe"
   },
   "source": [
    "### MLM pretraining\n",
    "\n",
    "Попробуйте улучшить качество, предварительно обучив выбранную модель на задачу **MLM** на обучающем датасете. Будет достаточно 1-2 эпох. Воспользуйтесь [примерами](https://github.com/huggingface/transformers/tree/main/examples/pytorch/language-modeling) из репозитория. Правильно организовав файл с обучающими данными, вы должны лишь воспользоваться готовым скриптом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-13T12:29:18.697325Z",
     "iopub.status.busy": "2025-03-13T12:29:18.697066Z",
     "iopub.status.idle": "2025-03-13T12:29:18.786942Z",
     "shell.execute_reply": "2025-03-13T12:29:18.786265Z",
     "shell.execute_reply.started": "2025-03-13T12:29:18.697304Z"
    },
    "id": "Yw5kALSEPi7K",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "with open('/kaggle/working/mlm.txt', 'a') as f:\n",
    "    for ln in train_concatenated:\n",
    "        f.write(f'{ln}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-13T12:29:18.788277Z",
     "iopub.status.busy": "2025-03-13T12:29:18.788017Z",
     "iopub.status.idle": "2025-03-13T12:29:18.791641Z",
     "shell.execute_reply": "2025-03-13T12:29:18.790888Z",
     "shell.execute_reply.started": "2025-03-13T12:29:18.788257Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# !python run_mlm.py --model_name_or_path DeepPavlov/rubert-base-cased --train_file mlm.txt --do_train --output_dir output/mlm --overwrite_output_dir --num_train_epochs 1 --per_device_train_batch_size  --save_steps 500 --logging_steps 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-13T12:29:18.792805Z",
     "iopub.status.busy": "2025-03-13T12:29:18.792594Z",
     "iopub.status.idle": "2025-03-13T12:29:18.882470Z",
     "shell.execute_reply": "2025-03-13T12:29:18.881253Z",
     "shell.execute_reply.started": "2025-03-13T12:29:18.792765Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module transformers has no attribute run_mlm",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-91809f5c38c2>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m transformers.run_mlm(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mmodel_name_or_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'DeepPavlov/rubert-base-cased'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtrain_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/kaggle/working/mlm.txt'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdo_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0moutput_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/kaggle/working'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1784\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"module {self.__name__} has no attribute {name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module transformers has no attribute run_mlm"
     ]
    }
   ],
   "source": [
    "transformers.run_mlm(\n",
    "    model_name_or_path='DeepPavlov/rubert-base-cased',\n",
    "    train_file='/kaggle/working/mlm.txt',\n",
    "    do_train=True,\n",
    "    output_dir='/kaggle/working',\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=16,\n",
    "    save_steps=500,\n",
    "    logging_steps=200\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TeorCVvePk0O"
   },
   "source": [
    "Обучите модель, полученную после процедуры **MLM** претрейна. Улучшилось ли качество?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-03-13T12:29:18.882982Z",
     "iopub.status.idle": "2025-03-13T12:29:18.883233Z",
     "shell.execute_reply": "2025-03-13T12:29:18.883131Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = Model().cuda()\n",
    "model.bert = AutoModel.from_pretrained('/kaggle/working/mlm.txt')\n",
    "loop(model)\n",
    "model.cpu()\n",
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t1UY9hnBRAIg"
   },
   "source": [
    "[Здесь](https://habr.com/ru/company/alfa/blog/669522/) можно прочитать подход от участников, занявших второе место в этом соревновании."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6853527,
     "sourceId": 11008544,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
